{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer"
      ],
      "metadata": {
        "id": "kdUQwzXl6itx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "구조\n",
        "- RNN, LSTM을 사용하지 않고 어텐션 기반으로 동작하는 인코더-디코더 구조의 모델\n",
        "- 인코더\n",
        "  - 입력 시퀀스를 받아들이며, 각 입력 단어에 대한 정보를 추출\n",
        "  - 멀티 헤드 어텐션과 피드포워드 네트워크로 구성됨\n",
        "- 디코더\n",
        "  - 인코드의 출력과 디코더의 이전 타임스텝 출력을 사용하여 다음 출력을 예측\n",
        "  - 멀티 헤드 어텐션, 피드포워드 네트워크, 셀프 어텐션으로 구성됨\n",
        "\n",
        "핵심 개념\n",
        "- 어텐션 메커니즘\n",
        "  - 셀프 어텐션: 입력의 각 위치가 다른 모든 위치의 정보를 고려하는 구조\n",
        "  - 멀티 헤드 어텐션: 여러 개의 독립적인 어텐션을 병렬로 수행하여 서로 다른 부분에 집중할 수 있도록 함\n",
        "- 포지셔널 인코딩: 트랜스포머는 입력의 순서를 학습할 수 없기 때문에 입력에 위치 정보를 추가해주어야 함\n",
        "- 병렬 처리 가능: 데이터를 순차적으로 입력하지 않고 동시에 병렬로 처리할 수 있기 때문에 빠르게 학습할 수 있음\n"
      ],
      "metadata": {
        "id": "7YsYgcJv6lfj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 셀프 어텐션 (Self Attention)"
      ],
      "metadata": {
        "id": "U-qOF_LH6v5G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Query, Key, Value 벡터로 입력을 변환\n",
        "\n",
        "Query와 Key의 내역을 통해 각 입력의 중요도를 계산한 후, 소프트맥스를 적용하여 확률을 출력\n",
        "\n",
        "각 Value에 확률(어텐션 가중치)를 곱하여 Weighted Sum을 계산\n"
      ],
      "metadata": {
        "id": "tXsUx2i7617P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 멀티 헤드 어텐션\n"
      ],
      "metadata": {
        "id": "7EpKUgar637z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "여러 개의 셀프 어텐션 블록을 병렬로 배치한 후 그 결과를 concat하는 방식"
      ],
      "metadata": {
        "id": "4fGdrR4765kk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer 구현하기"
      ],
      "metadata": {
        "id": "RfW2DhQi66yo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "모듈 임포트"
      ],
      "metadata": {
        "id": "21tq7Jn27Vhj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vid2pcL06Snn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터셋 클래스 준비"
      ],
      "metadata": {
        "id": "DBTrI_XW7XrY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 샘플 생성 (임의의 데이터셋 사용)\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=50):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # 토큰화 및 패딩\n",
        "        inputs = self.tokenizer(text, return_tensors='pt', max_length=self.max_len, padding='max_length', truncation=True)\n",
        "        input_ids = inputs['input_ids'].squeeze(0)\n",
        "        attention_mask = inputs['attention_mask'].squeeze(0)\n",
        "\n",
        "        # Attention mask를 boolean 타입으로 변환\n",
        "        attention_mask = attention_mask.bool()\n",
        "\n",
        "        return input_ids, attention_mask, torch.tensor(label)"
      ],
      "metadata": {
        "id": "CmN3qaZp7Hy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformer 모델 정의"
      ],
      "metadata": {
        "id": "1pYebpvP7gnK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 간단한 Transformer 모델 정의\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, num_classes, num_heads, num_layers, max_len):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.pos_encoder = nn.Embedding(max_len, embed_size)\n",
        "        self.transformer = nn.Transformer(d_model=embed_size, nhead=num_heads, num_encoder_layers=num_layers)\n",
        "        self.fc = nn.Linear(embed_size, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        seq_len = input_ids.size(1)\n",
        "        pos = torch.arange(0, seq_len).unsqueeze(0).to(input_ids.device)\n",
        "        x = self.embedding(input_ids) + self.pos_encoder(pos)\n",
        "        x = x.transpose(0, 1)  # Transformer expects input in (sequence, batch, feature) format\n",
        "        x = self.transformer(x, x, src_key_padding_mask=attention_mask)\n",
        "        x = x.mean(dim=0)  # Sequence-level representation\n",
        "        return self.fc(x)"
      ],
      "metadata": {
        "id": "ZPU3xeNy7JTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "하이퍼 파라미터 정의"
      ],
      "metadata": {
        "id": "rtVmisbI7k4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼파라미터\n",
        "vocab_size = 30522  # 임의의 토큰 개수 (BERT tokenizer 사용 시의 vocab_size)\n",
        "embed_size = 128\n",
        "num_classes = 2  # 이진 분류 예시\n",
        "num_heads = 8\n",
        "num_layers = 2\n",
        "max_len = 50"
      ],
      "metadata": {
        "id": "unQnxDim7kUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터셋 준비"
      ],
      "metadata": {
        "id": "b-hOr6nR7oc_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [\n",
        "    \"I absolutely love this new phone\",  # 1\n",
        "    \"This restaurant was terrible\",      # 2\n",
        "    \"I am very satisfied with the purchase\",  # 3\n",
        "    \"The movie was a complete waste of time\", # 4\n",
        "    \"What a beautiful day\",                    # 5\n",
        "    \"I hate rainy weather\",                    # 6\n",
        "    \"The staff was extremely friendly\",        # 7\n",
        "    \"I am disappointed with the product quality\", # 8\n",
        "    \"Everything about this experience was fantastic\", # 9\n",
        "    \"The food was cold and tasteless\",               # 10\n",
        "    \"This new software update is amazing\",            # 11\n",
        "    \"I regret ever buying this device\",               # 12\n",
        "    \"The wait time was acceptable\",                   # 13\n",
        "    \"It was a nightmare trying to find parking\",      # 14\n",
        "    \"I love the atmosphere of this place\",            # 15\n",
        "    \"The instructions were unclear and confusing\",    # 16\n",
        "    \"The quality is top-notch\",                       # 17\n",
        "    \"My order arrived damaged\",                       # 18\n",
        "    \"I had a wonderful time at the event\",            # 19\n",
        "    \"This is the worst day of my life\",               # 20\n",
        "    \"I am thrilled with the results\",                 # 21\n",
        "    \"They didn't provide any assistance\",             # 22\n",
        "    \"The design is sleek and modern\",                 # 23\n",
        "    \"The packaging was broken\",                       # 24\n",
        "    \"I feel so relaxed after using it\",               # 25\n",
        "    \"It's absolutely horrible\",                       # 26\n",
        "    \"I enjoy every moment here\",                      # 27\n",
        "    \"The shipping was delayed for weeks\",             # 28\n",
        "    \"The performance is outstanding\",                 # 29\n",
        "    \"I can't stand the noise in here\",                # 30\n",
        "    \"Great value for the price\",                      # 31\n",
        "    \"They charged me extra for no reason\",            # 32\n",
        "    \"I'm impressed by the customer service\",          # 33\n",
        "    \"I feel cheated by their false claims\",           # 34\n",
        "    \"The color looks stunning\",                       # 35\n",
        "    \"The product stopped working after a day\",        # 36\n",
        "    \"I highly recommend this brand\",                  # 37\n",
        "    \"They never respond to inquiries\",                # 38\n",
        "    \"The taste is absolutely delicious\",              # 39\n",
        "    \"The instructions were missing\",                  # 40\n",
        "    \"I will definitely buy this again\",               # 41\n",
        "    \"I want a refund\",                                # 42\n",
        "    \"The interface is user-friendly\",                 # 43\n",
        "    \"It gave me a terrible headache\",                 # 44\n",
        "    \"The seats were incredibly comfortable\",          # 45\n",
        "    \"They refused to help me\",                        # 46\n",
        "    \"Everything went smoothly\",                       # 47\n",
        "    \"It was a big disappointment\",                    # 48\n",
        "    \"I feel great after using this service\",          # 49\n",
        "    \"The website kept crashing\",                      # 50\n",
        "    \"They really went above and beyond\",              # 51\n",
        "    \"I am never going back there\",                    # 52\n",
        "    \"The flavor is just perfect\",                     # 53\n",
        "    \"The staff ignored me the whole time\",            # 54\n",
        "    \"It looks even better in person\",                 # 55\n",
        "    \"This place is so dirty\",                         # 56\n",
        "    \"My experience here was phenomenal\",              # 57\n",
        "    \"They lost my reservation\",                       # 58\n",
        "    \"I appreciate the prompt response\",               # 59\n",
        "    \"The screen flickers constantly\",                 # 60\n",
        "    \"It is the best gift I've ever received\",         # 61\n",
        "    \"Their attitude was condescending\",               # 62\n",
        "    \"I love how easy it is to set up\",                # 63\n",
        "    \"I can't believe how bad this turned out\",        # 64\n",
        "    \"The packaging was so cute\",                      # 65\n",
        "    \"It didn't match the description at all\",         # 66\n",
        "    \"I'm very happy with my purchase\",                # 67\n",
        "    \"The customer support was terrible\",              # 68\n",
        "    \"This is a game-changer\",                         # 69\n",
        "    \"The product feels cheap and flimsy\",             # 70\n",
        "    \"I can't wait to use it again\",                   # 71\n",
        "    \"They messed up my entire order\",                 # 72\n",
        "    \"So glad I found this item\",                      # 73\n",
        "    \"The lines were way too long\",                    # 74\n",
        "    \"They handled my request efficiently\",            # 75\n",
        "    \"The sound quality is awful\",                     # 76\n",
        "    \"I'm amazed by how well it works\",                # 77\n",
        "    \"It was a waste of money\",                        # 78\n",
        "    \"Truly the best experience I've had\",             # 79\n",
        "    \"I am completely unsatisfied\",                    # 80\n",
        "    \"They delivered faster than expected\",            # 81\n",
        "    \"The paint started peeling off immediately\",      # 82\n",
        "    \"The customer service agent was polite\",          # 83\n",
        "    \"I am furious about the lack of communication\",   # 84\n",
        "    \"I love the texture of this product\",             # 85\n",
        "    \"It arrived broken and unusable\",                 # 86\n",
        "    \"The staff made me feel welcomed\",                # 87\n",
        "    \"It's not worth the hype\",                        # 88\n",
        "    \"It was an unforgettable experience\",             # 89\n",
        "    \"I regret choosing this place\",                   # 90\n",
        "    \"I adore the packaging design\",                   # 91\n",
        "    \"They never apologized for the inconvenience\",    # 92\n",
        "    \"The user guide was extremely helpful\",           # 93\n",
        "    \"I was stuck with a defective item\",              # 94\n",
        "    \"I feel so satisfied with the outcome\",           # 95\n",
        "    \"The seats were filthy and uncomfortable\",        # 96\n",
        "    \"They resolved my issue quickly\",                 # 97\n",
        "    \"The website is confusing and slow\",              # 98\n",
        "    \"It's such a relief to find something this good\", # 99\n",
        "    \"I absolutely hate how it turned out\"             # 100\n",
        "]\n",
        "\n",
        "labels = [\n",
        "    1, # 1\n",
        "    0, # 2\n",
        "    1, # 3\n",
        "    0, # 4\n",
        "    1, # 5\n",
        "    0, # 6\n",
        "    1, # 7\n",
        "    0, # 8\n",
        "    1, # 9\n",
        "    0, # 10\n",
        "    1, # 11\n",
        "    0, # 12\n",
        "    1, # 13\n",
        "    0, # 14\n",
        "    1, # 15\n",
        "    0, # 16\n",
        "    1, # 17\n",
        "    0, # 18\n",
        "    1, # 19\n",
        "    0, # 20\n",
        "    1, # 21\n",
        "    0, # 22\n",
        "    1, # 23\n",
        "    0, # 24\n",
        "    1, # 25\n",
        "    0, # 26\n",
        "    1, # 27\n",
        "    0, # 28\n",
        "    1, # 29\n",
        "    0, # 30\n",
        "    1, # 31\n",
        "    0, # 32\n",
        "    1, # 33\n",
        "    0, # 34\n",
        "    1, # 35\n",
        "    0, # 36\n",
        "    1, # 37\n",
        "    0, # 38\n",
        "    1, # 39\n",
        "    0, # 40\n",
        "    1, # 41\n",
        "    0, # 42\n",
        "    1, # 43\n",
        "    0, # 44\n",
        "    1, # 45\n",
        "    0, # 46\n",
        "    1, # 47\n",
        "    0, # 48\n",
        "    1, # 49\n",
        "    0, # 50\n",
        "    1, # 51\n",
        "    0, # 52\n",
        "    1, # 53\n",
        "    0, # 54\n",
        "    1, # 55\n",
        "    0, # 56\n",
        "    1, # 57\n",
        "    0, # 58\n",
        "    1, # 59\n",
        "    0, # 60\n",
        "    1, # 61\n",
        "    0, # 62\n",
        "    1, # 63\n",
        "    0, # 64\n",
        "    1, # 65\n",
        "    0, # 66\n",
        "    1, # 67\n",
        "    0, # 68\n",
        "    1, # 69\n",
        "    0, # 70\n",
        "    1, # 71\n",
        "    0, # 72\n",
        "    1, # 73\n",
        "    0, # 74\n",
        "    1, # 75\n",
        "    0, # 76\n",
        "    1, # 77\n",
        "    0, # 78\n",
        "    1, # 79\n",
        "    0, # 80\n",
        "    1, # 81\n",
        "    0, # 82\n",
        "    1, # 83\n",
        "    0, # 84\n",
        "    1, # 85\n",
        "    0, # 86\n",
        "    1, # 87\n",
        "    0, # 88\n",
        "    1, # 89\n",
        "    0, # 90\n",
        "    1, # 91\n",
        "    0, # 92\n",
        "    1, # 93\n",
        "    0, # 94\n",
        "    1, # 95\n",
        "    0, # 96\n",
        "    1, # 97\n",
        "    0, # 98\n",
        "    1, # 99\n",
        "    0  # 100\n",
        "]"
      ],
      "metadata": {
        "id": "wr2EDBrx7nkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터셋 전처리"
      ],
      "metadata": {
        "id": "Wvcd8snj7v1n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sacremoses"
      ],
      "metadata": {
        "id": "QIn8-kG_7_2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 분할\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.2)\n",
        "\n",
        "tokenizer = torch.hub.load('huggingface/pytorch-transformers', 'tokenizer', 'bert-base-uncased')\n",
        "train_dataset = TextDataset(train_texts, train_labels, tokenizer, max_len=max_len)\n",
        "val_dataset = TextDataset(val_texts, val_labels, tokenizer, max_len=max_len)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16)"
      ],
      "metadata": {
        "id": "ASPcg43O7tau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 초기화 및 학습 설정"
      ],
      "metadata": {
        "id": "sukaRpvd8CRZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 초기화 및 학습 설정\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = TransformerModel(vocab_size, embed_size, num_classes, num_heads, num_layers, max_len).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "GWfZlM6074Nj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "훈련"
      ],
      "metadata": {
        "id": "hh-LTJVt8HP8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 루프\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for input_ids, attention_mask, labels in train_loader:\n",
        "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader)}\")"
      ],
      "metadata": {
        "id": "1UmqMh6m8GnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "평가"
      ],
      "metadata": {
        "id": "MpUCu2zA8Q-W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 평가\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for input_ids, attention_mask, labels in val_loader:\n",
        "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Validation Accuracy: {correct / total * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "qZoEANzv8JNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "추론"
      ],
      "metadata": {
        "id": "Y3ZI3RbI8Zjw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(text, model, tokenizer, max_len=50):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # 입력 문자열을 토크나이즈하고 attention mask 생성\n",
        "        inputs = tokenizer(text, return_tensors='pt', max_length=max_len, padding='max_length', truncation=True)\n",
        "        input_ids = inputs['input_ids'].squeeze(0).unsqueeze(0).to(device)  # 배치 차원 추가\n",
        "        attention_mask = inputs['attention_mask'].squeeze(0).unsqueeze(0).to(device)  # 배치 차원 추가\n",
        "\n",
        "        # Attention mask를 boolean 타입으로 변환\n",
        "        attention_mask = attention_mask.bool()\n",
        "\n",
        "        # 모델을 통해 추론\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    return predicted.item()"
      ],
      "metadata": {
        "id": "l7hiC5Pr8SZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 문자열 입력을 통해 추론\n",
        "input_text = \"I love it\"\n",
        "predicted_class = predict(input_text, model, tokenizer, max_len)\n",
        "print(f\"입력: {input_text}, 예측된 클래스: {predicted_class}\")"
      ],
      "metadata": {
        "id": "Ov6PkGN18bUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kv4rlCeg8bp4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
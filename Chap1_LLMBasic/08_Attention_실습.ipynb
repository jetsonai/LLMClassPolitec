{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Attention"
      ],
      "metadata": {
        "id": "f-WyqLE2aw1c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "입력 시퀀스 전체에서 중요한 정보를 선택적으로 참조할 수 있도록 하는 구조\n",
        "\n",
        "Seq2Seq 구조의 디코더에서 출력을 계산할 때 인코더의 hidden state 출력을 모두 사용"
      ],
      "metadata": {
        "id": "bgapJBOaa1Sy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 장점\n"
      ],
      "metadata": {
        "id": "o-nlUAoRbBCA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "긴 시퀀스 처리 능력 향상\n",
        "- 고정된 크기의 컨텍스트 벡터를 사용하지 않기 때문에 긴 시퀀스에서도 중요한 정보를 놓치지 않고 사용할 수 있음\n",
        "\n",
        "정렬 문제 해결\n",
        "- Seq2Seq 모델에서 입력과 출력 시퀀스 간의 단어 정렬 문제가 발생할 수 있는데, Attention은 각 단어 간의 상관관계를 학습하여 이를 해결함\n",
        "\n",
        "해석 가능\n",
        "- Attention 가중치를 통해 모델의 어느 부분에 집중하고 있는지 확인할 수 있음"
      ],
      "metadata": {
        "id": "yAjDotOTbErj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 단점"
      ],
      "metadata": {
        "id": "r7Em_406bI-Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "연산량 증가\n",
        "- Attention 메커니즘은 추가적인 연산을 요구하므로 모델의 복잡성이 증가함. 특히 대용량 데이터셋에서 계산 비용이 높아짐\n",
        "\n",
        "메모리 소모\n",
        "- 모든 입력 시퀀스를 저장해야 함, 시퀀스 길이가 길어질수록 메모리 사용량이 급격히 증가함\n",
        "\n",
        "훈련 속도 저하\n",
        "- 모델이 복잡해지는 만큼 학습 속도가 느려짐\n"
      ],
      "metadata": {
        "id": "4kB0bZlgbKJm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 종류"
      ],
      "metadata": {
        "id": "oeeFKq9SbMky"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 바다나우 어텐션 (Bahdanau Attention)\n"
      ],
      "metadata": {
        "id": "1CdxcmBEbPHV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hidden state 결함\n",
        "- 디코더의 이전 은닉 상태와 인코더의 각 은닉 상태를 결합한 후 비선형 변환을 통해 어텐션 가중치를 계산\n",
        "\n",
        "Additive 방식\n",
        "- 디코더 은닉 상태 계산 이전에 어텐션 적용\n",
        "- 은닉 상태를 더한 후, 특정 가중치 행렬을 사용하여 점수를 계산"
      ],
      "metadata": {
        "id": "poQZG0S2bQCv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 룽 어텐션 (Luong Attention)\n"
      ],
      "metadata": {
        "id": "tBap2qF2bRm0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "은닉 상태 내적\n",
        "- 디코더의 현재 은닉 상태와 인코더의 은닉 상태 간의 내역을 사용해 어텐션 가중치를 계산. 바다나우 어텐션보다 계산이 효율적임\n",
        "\n",
        "Multiplicative 방식\n",
        "- 디코더 은닉 상태 계산 이후에 어텐션 적용\n",
        "- 두 은닉 상태를 내적하는 방식으로 컨텍스트 벡터 생성"
      ],
      "metadata": {
        "id": "DDFt_LvRbTIU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 바다나우 어텐션 구현"
      ],
      "metadata": {
        "id": "o4i7ieE-bYih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "class BahdanauAttention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.W1 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.W2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.V = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        # hidden: [batch_size, hidden_size]\n",
        "        # encoder_outputs: [batch_size, seq_len, hidden_size]\n",
        "\n",
        "        hidden = hidden.unsqueeze(1)  # [batch_size, 1, hidden_size]\n",
        "        score = self.V(torch.tanh(self.W1(encoder_outputs) + self.W2(hidden))) # [batch_size,seq_len,1]\n",
        "\n",
        "        attn_weights = torch.softmax(score, dim=1)  # [batch_size, seq_len, 1]\n",
        "        context_vector = attn_weights * encoder_outputs  # [batch_size, seq_len, hidden_size]\n",
        "        context_vector = torch.sum(context_vector, dim=1)  # [batch_size, hidden_size]\n",
        "\n",
        "        return context_vector, attn_weights"
      ],
      "metadata": {
        "id": "Wvdyr_Dkbb0w"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 룽 어텐션 구현"
      ],
      "metadata": {
        "id": "GYAySu-jbdx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "class LuongAttention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(LuongAttention, self).__init__()\n",
        "        self.attn = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        # hidden: [batch_size, hidden_size]\n",
        "        # encoder_outputs: [batch_size, seq_len, hidden_size]\n",
        "\n",
        "        # 어텐션 가중치 계산\n",
        "        hidden = self.attn(hidden).unsqueeze(1)  # [batch_size, 1, hidden_size]\n",
        "        scores = torch.bmm(hidden, encoder_outputs.transpose(1, 2))  # [batch_size, 1, seq_len]\n",
        "        attn_weights = F.softmax(scores, dim=2)  # [batch_size, 1, seq_len]\n",
        "\n",
        "        # 컨텍스트 벡터 계산\n",
        "        context = torch.bmm(attn_weights, encoder_outputs)  # [batch_size, 1, hidden_size]\n",
        "        return context, attn_weights"
      ],
      "metadata": {
        "id": "LJf8_dGkbfKK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attention 기반 번역 모델 구현"
      ],
      "metadata": {
        "id": "LSfs9AL8boo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 인코더 클래스"
      ],
      "metadata": {
        "id": "YNDKGlUObuYx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uRfBopPZZlrN"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_vocab_size, embed_size, hidden_size, num_layers=1):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(input_vocab_size, embed_size)\n",
        "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [batch_size, seq_len]\n",
        "        embedded = self.embedding(x)  # [batch_size, seq_len, embed_size]\n",
        "        outputs, (hidden, cell) = self.lstm(embedded)  # outputs: [batch_size, seq_len, hidden_size]\n",
        "        return outputs, (hidden, cell)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 디코더 클래스"
      ],
      "metadata": {
        "id": "87Uek4YQbx1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, target_vocab_size, embed_size, hidden_size, num_layers=1):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(target_vocab_size, embed_size)\n",
        "        self.lstm = nn.LSTM(embed_size + hidden_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.attention = BahdanauAttention(hidden_size)\n",
        "        self.fc = nn.Linear(hidden_size, target_vocab_size)\n",
        "\n",
        "    def forward(self, input_step, hidden, cell, encoder_outputs):\n",
        "        embedded = self.embedding(input_step)  # [batch_size, embed_size]\n",
        "        embedded = embedded.unsqueeze(1)  # [batch_size, 1, embed_size]\n",
        "\n",
        "        context_vector, attn_weights = self.attention(hidden[-1], encoder_outputs)\n",
        "\n",
        "        lstm_input = torch.cat((embedded, context_vector.unsqueeze(1)), dim=2)  # [batch_size, 1, embed_size + hidden_size]\n",
        "        output, (hidden, cell) = self.lstm(lstm_input, (hidden, cell))\n",
        "\n",
        "\n",
        "        output = self.fc(output.squeeze(1))  # [batch_size, target_vocab_size]\n",
        "        output = F.log_softmax(output, dim=1)\n",
        "        return output, hidden, cell, attn_weights"
      ],
      "metadata": {
        "id": "UtLp9r4ibxPl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Seq2Seq 클래스 정의"
      ],
      "metadata": {
        "id": "P1RSUvAEcCv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, source, target, teacher_forcing_ratio=0.5):\n",
        "        batch_size = source.size(0)\n",
        "        tgt_len = target.size(1)\n",
        "        tgt_vocab_size = self.decoder.fc.out_features\n",
        "\n",
        "        outputs = torch.zeros(batch_size, tgt_len, tgt_vocab_size).to(self.device)\n",
        "        encoder_outputs, (hidden, cell) = self.encoder(source)\n",
        "\n",
        "        input_step = target[:, 0]  # [batch_size]\n",
        "\n",
        "        for t in range(1, tgt_len):\n",
        "            # 디코더를 통해 다음 단어 예측\n",
        "            output, hidden, cell, attn_weights = self.decoder(input_step, hidden, cell, encoder_outputs)\n",
        "            outputs[:, t] = output\n",
        "            # 교사 강요 적용 여부 결정\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            top1 = output.argmax(1)  # [batch_size]\n",
        "            input_step = target[:, t] if teacher_force else top1\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "yKsLgtrzb0Q7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 실습"
      ],
      "metadata": {
        "id": "2zBOmMnkccxv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "강의자료를 바탕으로 어텐션 구조를 적용한 Seq2Seq 훈련 코드를 작성하고 훈련을 수행해보시오"
      ],
      "metadata": {
        "id": "34PTVvHiceNZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "    ('je suis etudiant', 'i am a student'),\n",
        "    ('j aime le football', 'i love football'),\n",
        "    ('il fait beau aujourd hui', 'it is nice today'),\n",
        "    ('je mange une pomme', 'i eat an apple'),\n",
        "    ('nous aimons apprendre', 'we love learning'),\n",
        "    ('je vais à l école', 'i go to school'),\n",
        "    ('tu es mon ami', 'you are my friend'),\n",
        "    ('elle lit un livre', 'she is reading a book'),\n",
        "    ('il écrit une lettre', 'he is writing a letter'),\n",
        "    ('nous regardons un film', 'we are watching a movie'),\n",
        "    ('vous parlez français', 'you speak french'),\n",
        "    ('ils jouent au tennis', 'they play tennis'),\n",
        "    ('je fais du sport', 'i do sports'),\n",
        "    ('tu écoutes de la musique', 'you listen to music'),\n",
        "    ('elle cuisine un gâteau', 'she is baking a cake'),\n",
        "    ('il conduit une voiture', 'he is driving a car'),\n",
        "    ('nous visitons le musée', 'we are visiting the museum'),\n",
        "    ('vous aimez la plage', 'you love the beach'),\n",
        "    ('ils dansent bien', 'they dance well'),\n",
        "    ('je prends le train', 'i take the train'),\n",
        "    ('tu joues de la guitare', 'you play the guitar'),\n",
        "    ('elle dessine un portrait', 'she draws a portrait'),\n",
        "    ('il apprend l anglais', 'he learns english'),\n",
        "    ('nous voyageons en avion', 'we travel by plane'),\n",
        "    ('vous travaillez dur', 'you work hard'),\n",
        "    ('ils étudient la biologie', 'they study biology'),\n",
        "    ('je bois du café', 'i drink coffee'),\n",
        "    ('tu manges du pain', 'you eat bread'),\n",
        "    ('elle porte une robe', 'she wears a dress'),\n",
        "    ('il lit le journal', 'he reads the newspaper'),\n",
        "    ('nous aimons la nature', 'we love nature'),\n",
        "    ('vous prenez le bus', 'you take the bus'),\n",
        "    ('ils chantent une chanson', 'they sing a song'),\n",
        "    ('je visite Paris', 'i visit paris'),\n",
        "    ('tu écris un poème', 'you write a poem'),\n",
        "    ('elle étudie la médecine', 'she studies medicine'),\n",
        "    ('il fait ses devoirs', 'he does his homework'),\n",
        "    ('nous préparons le dîner', 'we prepare dinner'),\n",
        "    ('vous jouez au basketball', 'you play basketball'),\n",
        "    ('ils regardent la télévision', 'they watch television'),\n",
        "    ('je dors bien', 'i sleep well'),\n",
        "    ('tu travailles dans un bureau', 'you work in an office'),\n",
        "    ('elle nage dans la piscine', 'she swims in the pool'),\n",
        "    ('il se réveille tôt', 'he wakes up early'),\n",
        "    ('nous chantons ensemble', 'we sing together'),\n",
        "    ('vous écrivez des emails', 'you write emails'),\n",
        "    ('ils jouent aux cartes', 'they play cards'),\n",
        "    ('je visite un parc', 'i visit a park'),\n",
        "    ('tu fais du vélo', 'you ride a bike'),\n",
        "    ('elle regarde les étoiles', 'she watches the stars'),\n",
        "    ('il monte les escaliers', 'he climbs the stairs'),\n",
        "    ('nous lisons un roman', 'we read a novel'),\n",
        "    ('vous écoutez la radio', 'you listen to the radio'),\n",
        "    ('ils se promènent en ville', 'they walk around the city'),\n",
        "    ('je cours dans le parc', 'i run in the park'),\n",
        "    ('tu achètes des légumes', 'you buy vegetables'),\n",
        "    ('elle joue au volley', 'she plays volleyball'),\n",
        "    ('il nettoie la maison', 'he cleans the house'),\n",
        "    ('nous prenons le petit déjeuner', 'we have breakfast'),\n",
        "    ('vous apprenez une nouvelle langue', 'you learn a new language'),\n",
        "    ('ils font la cuisine', 'they cook'),\n",
        "    ('je dessine une maison', 'i draw a house'),\n",
        "    ('tu regardes un documentaire', 'you watch a documentary'),\n",
        "    ('elle visite un château', 'she visits a castle'),\n",
        "    ('il photographie le paysage', 'he photographs the landscape'),\n",
        "    ('nous organisons une fête', 'we organize a party'),\n",
        "    ('vous jouez aux échecs', 'you play chess'),\n",
        "    ('ils courent ensemble', 'they run together'),\n",
        "    ('je regarde un match de football', 'i watch a football match'),\n",
        "    ('tu lis un magazine', 'you read a magazine'),\n",
        "    ('elle prépare une salade', 'she makes a salad'),\n",
        "    ('il voyage en train', 'he travels by train'),\n",
        "    ('nous faisons du shopping', 'we go shopping'),\n",
        "    ('vous dansez au club', 'you dance at the club'),\n",
        "    ('ils étudient l histoire', 'they study history'),\n",
        "    ('je visite le marché', 'i visit the market'),\n",
        "    ('tu achètes un cadeau', 'you buy a gift'),\n",
        "    ('elle travaille dans une école', 'she works in a school'),\n",
        "    ('il joue du piano', 'he plays the piano'),\n",
        "    ('nous regardons le coucher du soleil', 'we watch the sunset'),\n",
        "    ('vous apprenez à cuisiner', 'you learn to cook'),\n",
        "    ('ils se reposent après le travail', 'they rest after work'),\n",
        "    ('je prends des photos', 'i take photos'),\n",
        "    ('tu fais de la natation', 'you go swimming'),\n",
        "    ('elle sourit toujours', 'she always smiles'),\n",
        "    ('il étudie à l université', 'he studies at the university'),\n",
        "    ('nous visitons nos amis', 'we visit our friends'),\n",
        "    ('vous mangez au restaurant', 'you eat at the restaurant'),\n",
        "    ('ils jouent dans le jardin', 'they play in the garden'),\n",
        "    ('je prends des notes', 'i take notes'),\n",
        "    ('tu conduis prudemment', 'you drive carefully'),\n",
        "    ('elle chante magnifiquement', 'she sings beautifully'),\n",
        "    ('il lit un roman policier', 'he reads a detective novel'),\n",
        "    ('nous partons en vacances', 'we go on vacation'),\n",
        "    ('vous regardez les étoiles', 'you watch the stars'),\n",
        "    ('ils écoutent de la musique classique', 'they listen to classical music'),\n",
        "    ('je prépare un café', 'i make a coffee'),\n",
        "    ('tu joues avec ton chien', 'you play with your dog'),\n",
        "    ('elle porte des lunettes', 'she wears glasses'),\n",
        "    ('il aime le chocolat', 'he loves chocolate')\n",
        "]"
      ],
      "metadata": {
        "id": "DGXtWh8JcMTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DJnbmGsQcqtJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
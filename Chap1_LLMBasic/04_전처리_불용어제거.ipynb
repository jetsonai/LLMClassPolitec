{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 불용어 제거 (Stop-word Removal)"
      ],
      "metadata": {
        "id": "fVwnohI2r9HC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 문장에 자주 등장하지만, 문장의 주요 의미를 파악하는 데 큰 도움이 되지 않는 단어를 의미\n",
        "  - 주로 조사, 접속사, 관사 등이 이에 해당함\n",
        "    - 영어 예시: ‘a’, ‘an’, ‘the’, ‘in’, ‘on’, ‘and’, ‘but’ 등\n",
        "    - 한국어 예시: ‘은’, ‘는‘, ‘이‘, ‘가‘, ‘를‘, ‘을‘, ‘에‘, ‘의‘, ‘도’, ‘로‘ 등\n",
        "- 불용어 제거의 장단점\n",
        "  - 장점\n",
        "    - 연산 속도 향상: 처리해야 할 단어 수가 줄어들어 연산 속도 빨라짐\n",
        "    - 모델의 일반화 능력 향상: 불필요한 단어에 의한 과적합 방지\n",
        "  - 단점\n",
        "    - 의미 손실 가능성: 불용어로 간주되어 삭제된 단어가 문맥 이해해 중요한 역할을 하는 경우가 있음\n",
        "    - 언어 및 도메인 의존성: 일반적인 불용어 리스트가 특정 도메인이나 언어에 적합하지 않을 수 있음"
      ],
      "metadata": {
        "id": "Ic5xVXD9ufhT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## nltk를 이용한 불용어 제거"
      ],
      "metadata": {
        "id": "jtz7EuhjunzY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "dzs_wa8Ou605"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ZWhRDYcrrOb"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# 예제 텍스트\n",
        "text = \"This is a sample sentence, showing off the stop words filtration.\"\n",
        "\n",
        "# 단어 토큰화\n",
        "words = word_tokenize(text)\n",
        "print(\"원본 단어들:\", words)\n",
        "\n",
        "# 영어 불용어 목록 가져오기\n",
        "stop_words = set(stopwords.words('english'))\n",
        "print(\"불용어 목록:\", list(stop_words)[:10])  # 일부만 출력\n",
        "\n",
        "# 불용어 제거\n",
        "filtered_words = [word for word in words if word.lower() not in stop_words]\n",
        "print(\"불용어 제거 후 단어들:\", filtered_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KoNLPy를 이용한 불용어 제거"
      ],
      "metadata": {
        "id": "DsI2pEtqvRXd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install konlpy"
      ],
      "metadata": {
        "id": "rNv1m3IzvY8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Okt\n",
        "\n",
        "# 형태소 분석기 객체 생성\n",
        "okt = Okt()\n",
        "\n",
        "# 예제 텍스트\n",
        "text = \"자연어 처리는 인공지능의 한 분야로서, 인간의 언어를 이해하고 처리합니다.\"\n",
        "\n",
        "# 토큰화\n",
        "tokens = okt.morphs(text)\n",
        "print(\"원본 토큰들:\", tokens)\n",
        "\n",
        "# 불용어 제거\n",
        "stop_words = ['은', '는', '이', '가', '을', '를', '에', '의', '도', '으로서', '하고', '합니다', ',', '.']\n",
        "filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "print(\"불용어 제거 후 토큰들:\", filtered_tokens)"
      ],
      "metadata": {
        "id": "_acxSGjOvRN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 불용어 리스트의 커스터마이징"
      ],
      "metadata": {
        "id": "6UzOIXg5vcWt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "특정 도메인에서는 일반적인 불용어 외에도 해당 분야에서 자주 사용되어 중요도가 낮은 단어를 추가로 제거할 수 있음\n",
        "\n",
        "```\n",
        "domain_stop_words = ['오늘', '진짜', '정말', '많이', '이렇게']\n",
        "stop_words.extend(domain_stop_words)\n",
        "```"
      ],
      "metadata": {
        "id": "-9zS7sImvhQq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 불용어 제거의 영향 확인"
      ],
      "metadata": {
        "id": "8BTbPma2vn9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from konlpy.tag import Okt\n",
        "okt = Okt()\n",
        "text = \"자연어 처리는 인공지능의 한 분야로서, 인간의 언어를 이해하고 처리합니다.\"\n",
        "tokens = okt.morphs(text)\n",
        "print(\"원본 토큰들: \", tokens)\n",
        "word_counts = Counter(tokens)\n",
        "print(\"불용어 제거 전 단어 빈도수: \", word_counts)\n",
        "stop_words = ['은', '는', '이', '가', '을', '를', '에', '의', '도', '으로서', '하고', '합니다', ',', '.']\n",
        "filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "filtered_word_counts = Counter(filtered_tokens)\n",
        "print(\"불용어 제거 후 단어 빈도수: \", filtered_word_counts)"
      ],
      "metadata": {
        "id": "Nz7UsGAbvrl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "불용어 제거 전/후의 단어 빈도수를 비교하여 불용어 제거가 데이터에 미치는 영향을 확인할 수 있음"
      ],
      "metadata": {
        "id": "stD5eqvFvq4S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 실습"
      ],
      "metadata": {
        "id": "EpdWJGzEu4i4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 불용어 제거 적용하기"
      ],
      "metadata": {
        "id": "E4b2F1I_wUIX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이전에 실습한 내용을 참고하여 주어진 토큰 리스트에서 불용어를 제거하세요. 불용어 목록은 ['is', 'a', 'the', 'of', 'and']입니다.\n",
        "\n",
        "예시 입력\n",
        "\n",
        "```\n",
        "tokens = ['This', 'is', 'a', 'sample', 'of', 'text', 'and', 'tokenization', '.']\n",
        "```\n",
        "목표 출력\n",
        "\n",
        "```\n",
        "['This', 'sample', 'text', 'tokenization', '.']\n",
        "```"
      ],
      "metadata": {
        "id": "SaraF7a0wUrZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B-mEHECSu5B5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 불용어 제거 적용하기"
      ],
      "metadata": {
        "id": "r09UH-YuwV76"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이전에 실습한 내용을 참고하여 주어진 토큰 리스트에서 불용어를 제거하고, 제거한 후의 단어 빈도 수를 확인하시오\n",
        "\n",
        "예시 입력\n",
        "\n",
        "```\n",
        "sentences = [\n",
        "    \"오늘 날씨가 정말 좋네요.\",\n",
        "    \"저는 자연어 처리를 공부하고 있습니다.\",\n",
        "    \"데이터 분석은 재미있지만 어려워요.\",\n",
        "    \"파이썬은 정말 강력한 프로그래밍 언어입니다.\"]\n",
        "```\n",
        "\n",
        "목표 출력\n",
        "\n",
        "```\n",
        "단어 빈도수: Counter({'오늘': 1, '날씨': 1, '좋네요': 1, '저': 1, '자연어': 1, '처리': 1, '공부': 1, '데이터': 1, '분석': 1, '재미있지만': 1, '어려워요': 1, '파이썬': 1, '강력한': 1, '프로그래밍': 1, '언어': 1})\n",
        "```"
      ],
      "metadata": {
        "id": "ALLxeqT4wfJw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xXkwOjgnwd-p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
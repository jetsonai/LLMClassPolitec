{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# BERT"
      ],
      "metadata": {
        "id": "-MlGawR39quP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "구글에서 개발한 자연어 처리 모델로, Transformer 구조에 기반한 사전 학습 언어 모델"
      ],
      "metadata": {
        "id": "ivOrIQeN9ulv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "핵심 개념\n",
        "- Bidirectional (양방향)\n",
        "  - 입력된 문장을 양방향으로 처리함. 문장의 왼쪽에서 오른쪽, 오른쪽에서 왼쪽으로 동시에 학습\n",
        "  - 문맥을 더 잘 추론할 수 있게 됩\n",
        "- Transformer 기반\n",
        "  - Encoder 부분만을 사용한 모델.\n",
        "  - 문장 내의 중요한 단어와 덜 중요한 단어를 구분하고 이를 기반으로 문장의 의미를 학습\n",
        "\n",
        "파생 모델\n",
        "- ALBERT (A Lite BERT for Self-supervised Learning of Language Representations)\n",
        "- RoBERTa (A Robustly Optimized BERT Pretraining Approach)\n",
        "- ELECTRA (Efficiently Learning an Encoder that Classifies Token Replacements Accurately)"
      ],
      "metadata": {
        "id": "w-ebB2ak9wIL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BERT를 이용한 감정 분류기 훈련"
      ],
      "metadata": {
        "id": "CNmggOoE92Qx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "9Lx6bf_j-CnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모듈 준비"
      ],
      "metadata": {
        "id": "Fma2jv-QAIoh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RR0L3ish8-8h"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from datasets import load_dataset\n",
        "from torch.optim import AdamW"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터셋 준비"
      ],
      "metadata": {
        "id": "iZafAQ5OAFhL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 데이터셋 로드\n",
        "dataset = load_dataset(\"imdb\")\n",
        "train_dataset = dataset['train'].shuffle(seed=42).select(range(1000))  # 빠른 실습을 위해 1000개 샘플만 사용\n",
        "test_dataset = dataset['test'].shuffle(seed=42).select(range(500))\n",
        "\n",
        "# 2. 토크나이저 설정 (BERT-base)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# 3. 토큰화 함수 정의\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
        "\n",
        "# 4. 데이터셋 토큰화\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# 5. 텐서로 변환\n",
        "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=8)"
      ],
      "metadata": {
        "id": "tdfZi1yK98iR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 준비"
      ],
      "metadata": {
        "id": "HwRwUv8sAQXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. BERT 모델 로드 (2개 클래스용)\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
        "\n",
        "# 7. 디바이스 설정 (GPU가 있으면 GPU로 설정)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# 8. 옵티마이저 설정\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)"
      ],
      "metadata": {
        "id": "Zt1bP40oAPTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "훈련 함수 정의"
      ],
      "metadata": {
        "id": "n5F3szbJAWlD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. 학습 함수 정의\n",
        "def train(model, dataloader):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    for batch in dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['label'].to(device)\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        _, preds = torch.max(outputs.logits, dim=1)\n",
        "        correct += torch.sum(preds == labels)\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    accuracy = correct.double() / len(dataloader.dataset)\n",
        "\n",
        "    return avg_loss, accuracy"
      ],
      "metadata": {
        "id": "Ujo4Uqc5ATno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "평가 함수 정의"
      ],
      "metadata": {
        "id": "14-yj2c3AaN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. 평가 함수 정의\n",
        "def evaluate(model, dataloader):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            _, preds = torch.max(outputs.logits, dim=1)\n",
        "            correct += torch.sum(preds == labels)\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    accuracy = correct.double() / len(dataloader.dataset)\n",
        "\n",
        "    return avg_loss, accuracy"
      ],
      "metadata": {
        "id": "FMNiTTYWAZLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "훈련 및 평가"
      ],
      "metadata": {
        "id": "md-KXsU8AeVg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. 학습 및 평가\n",
        "epochs = 3\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "\n",
        "    train_loss, train_acc = train(model, train_dataloader)\n",
        "    print(f\"Train Loss: {train_loss:.3f}, Train Accuracy: {train_acc:.3f}\")\n",
        "\n",
        "    val_loss, val_acc = evaluate(model, test_dataloader)\n",
        "    print(f\"Validation Loss: {val_loss:.3f}, Validation Accuracy: {val_acc:.3f}\")"
      ],
      "metadata": {
        "id": "dpBbgw6XAfEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "추론 함수 정의\n"
      ],
      "metadata": {
        "id": "68Ii9FL4AiTR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 12. 추론 함수 정의 (입력된 텍스트의 감정을 예측)\n",
        "def predict(text, model, tokenizer):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=128).to(device)\n",
        "        outputs = model(**inputs)\n",
        "        _, predicted_class = torch.max(outputs.logits, dim=1)\n",
        "        return predicted_class.item()"
      ],
      "metadata": {
        "id": "w42Amk_NAgbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "추론"
      ],
      "metadata": {
        "id": "EL6rWmt-Anf_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 13. 예시 추론\n",
        "sample_text = \"I really loved this movie, it was fantastic!\"\n",
        "predicted_label = predict(sample_text, model, tokenizer)\n",
        "print(f\"입력 텍스트: \\\"{sample_text}\\\"\")\n",
        "print(f\"예측된 레이블: {'긍정' if predicted_label == 1 else '부정'}\")"
      ],
      "metadata": {
        "id": "w2AE7ELfAn4A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}

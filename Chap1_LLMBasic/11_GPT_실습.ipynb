{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# GPT-2를 이용한 문장 생성"
      ],
      "metadata": {
        "id": "9rt6Z3WbGWUJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "환경 구성 및 모듈 임포트"
      ],
      "metadata": {
        "id": "Jyw21GkoGX4b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AiBdkiQQGPHQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import GPT2LMHeadModel, PreTrainedTokenizerFast"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 한국어 GPT-2 모델 및 토크나이저 로드\n",
        "model_name = 'skt/kogpt2-base-v2'\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "tokenizer = PreTrainedTokenizerFast.from_pretrained(model_name)\n",
        "\n",
        "# 2. 모델을 GPU로 이동 (가능할 경우)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "SIY3yQFkGebH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. 문장 생성 함수 정의\n",
        "def generate_text(prompt, max_length=50):\n",
        "    # 입력 문장을 토큰화하고 텐서로 변환\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors='pt').to(device)\n",
        "\n",
        "    # 모델을 통해 텍스트 생성\n",
        "    output = model.generate(\n",
        "        input_ids,\n",
        "        max_length=max_length,\n",
        "        do_sample=True,  # 샘플링 방식으로 생성\n",
        "        top_k=50,        # 상위 50개 단어만 고려\n",
        "        top_p=0.95,      # 누적 확률이 95%인 단어들만 고려\n",
        "        repetition_penalty=2.0,  # 반복을 줄이기 위한 패널티\n",
        "        no_repeat_ngram_size=3,  # 같은 n-그램 반복 방지\n",
        "        pad_token_id=tokenizer.pad_token_id,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "        bos_token_id=tokenizer.bos_token_id\n",
        "    )\n",
        "\n",
        "    # 생성된 텍스트를 디코딩하여 반환\n",
        "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    return generated_text"
      ],
      "metadata": {
        "id": "rnhySCZ3Ge8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. 샘플 문장 생성\n",
        "prompt = \"인공지능은\"\n",
        "generated_text = generate_text(prompt, max_length=100)\n",
        "\n",
        "print(f\"입력 문장: {prompt}\")\n",
        "print(f\"생성된 문장: {generated_text}\")"
      ],
      "metadata": {
        "id": "y6DgzT6GGh6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "13Jp5jG_Gs5f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}